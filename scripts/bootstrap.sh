#!/usr/bin/env bash
set -euo pipefail

echo "ğŸš€ TalentPulse Bootstrap"
echo "========================"

# â”€â”€ 1. Copy .env if missing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if [ ! -f .env ]; then
    cp .env.example .env
    echo "âœ… Created .env from .env.example"
fi

# â”€â”€ 2. Check Ollama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OLLAMA_URL="${OLLAMA_BASE_URL:-http://localhost:11434}"
OLLAMA_MODEL="${OLLAMA_MODEL:-llama3.1:8b}"

echo ""
echo "ğŸ” Checking Ollama at $OLLAMA_URL ..."

OLLAMA_AVAILABLE=false
if curl -s --connect-timeout 3 "$OLLAMA_URL/api/tags" > /dev/null 2>&1; then
    echo "âœ… Ollama is running"
    OLLAMA_AVAILABLE=true

    # Check if model exists
    if curl -s "$OLLAMA_URL/api/tags" | grep -q "$OLLAMA_MODEL"; then
        echo "âœ… Model $OLLAMA_MODEL is available"
    else
        echo "ğŸ“¥ Pulling model $OLLAMA_MODEL (this may take a while)..."
        curl -s "$OLLAMA_URL/api/pull" -d "{\"name\": \"$OLLAMA_MODEL\"}" > /dev/null 2>&1 &
        echo "   Pull started in background. LLM features will be available once complete."
    fi
else
    echo "âš ï¸  Ollama not reachable at $OLLAMA_URL"
    echo "   â†’ TalentPulse will run in TEMPLATE FALLBACK mode"
    echo "   â†’ Install: brew install ollama && ollama serve"
    echo ""
fi

# â”€â”€ 3. Bring up Docker Compose â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "ğŸ³ Starting Docker services..."
docker compose up -d --build

# â”€â”€ 4. Wait for API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "â³ Waiting for API to be ready..."
for i in {1..30}; do
    if curl -s http://localhost:8000/health > /dev/null 2>&1; then
        echo "âœ… API is healthy"
        break
    fi
    sleep 2
done

# â”€â”€ 5. Seed demo data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "ğŸŒ± Seeding demo data..."
curl -s -X POST http://localhost:8000/sync/run | python3 -m json.tool 2>/dev/null || \
    curl -s -X POST http://localhost:8000/sync/run

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ‰ TalentPulse is ready!"
echo ""
echo "   ğŸ–¥  Dashboard:  http://localhost:3000"
echo "   ğŸ“¡ API docs:   http://localhost:8000/docs"
echo "   â¤ï¸  Health:     http://localhost:8000/health"
echo ""
if [ "$OLLAMA_AVAILABLE" = true ]; then
    echo "   ğŸ¤– Ollama:     Connected (LLM features active)"
else
    echo "   ğŸ¤– Ollama:     Not connected (template fallback active)"
fi
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
